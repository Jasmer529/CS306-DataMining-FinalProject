"""
ç”µå•†ç”¨æˆ·è¡Œä¸ºæ¨èç³»ç»Ÿä¸»ç¨‹åº
æ•´åˆç”¨æˆ·åˆ†æã€å¤šç®—æ³•æ¨èã€å¯è§†åŒ–ç­‰åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import warnings
from datetime import datetime
import os
import sys

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from user_analysis_enhancement import UserAnalysisEnhancer
from collaborative_filtering import CollaborativeFiltering
from transformer_recommender import TransformerRecommender

warnings.filterwarnings('ignore')

class ECommerceRecommenderSystem:
    """ç”µå•†æ¨èç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, data_path=None):
        """
        åˆå§‹åŒ–æ¨èç³»ç»Ÿ
        :param data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.data_path = data_path
        self.data = None
        self.user_analyzer = None
        self.algorithms = {}
        self.results = {}
        
        print("ğŸ›’ ç”µå•†ç”¨æˆ·è¡Œä¸ºæ¨èç³»ç»Ÿ")
        print("=" * 60)
        
    def load_data(self, data_path=None):
        """åŠ è½½æ•°æ®"""
        if data_path:
            self.data_path = data_path
            
        if not self.data_path:
            print("âŒ è¯·æŒ‡å®šæ•°æ®æ–‡ä»¶è·¯å¾„")
            return False
            
        try:
            print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®: {self.data_path}")
            self.data = pd.read_csv(self.data_path)
            
            # æ•°æ®é¢„å¤„ç†
            if 'datetime' not in self.data.columns and 'timestamp' in self.data.columns:
                self.data['datetime'] = pd.to_datetime(self.data['timestamp'], unit='s')
            elif 'datetime' in self.data.columns:
                self.data['datetime'] = pd.to_datetime(self.data['datetime'])
            
            # æ·»åŠ æ—¶é—´ç‰¹å¾
            if 'datetime' in self.data.columns:
                self.data['date'] = self.data['datetime'].dt.date
                self.data['hour'] = self.data['datetime'].dt.hour
                self.data['day_of_week'] = self.data['datetime'].dt.day_of_week
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
            print(f"   ğŸ“Š æ€»è®°å½•æ•°: {len(self.data):,}")
            print(f"   ğŸ‘¥ ç”¨æˆ·æ•°é‡: {self.data['user_id'].nunique():,}")
            print(f"   ğŸ›ï¸ å•†å“æ•°é‡: {self.data['item_id'].nunique():,}")
            
            if 'category_id' in self.data.columns:
                print(f"   ğŸ·ï¸ å“ç±»æ•°é‡: {self.data['category_id'].nunique():,}")
                
            behavior_counts = self.data['behavior_type'].value_counts()
            print(f"   ğŸ¯ è¡Œä¸ºåˆ†å¸ƒ: {dict(behavior_counts)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def analyze_users(self):
        """ç”¨æˆ·è¡Œä¸ºåˆ†æ"""
        if self.data is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return
            
        print("\n" + "="*50)
        print("ğŸ‘¥ å¼€å§‹ç”¨æˆ·è¡Œä¸ºåˆ†æ")
        print("="*50)
        
        # åˆå§‹åŒ–ç”¨æˆ·åˆ†æå™¨
        self.user_analyzer = UserAnalysisEnhancer(self.data)
        
        # 1. RFMåˆ†æ
        print("\nğŸ” è¿›è¡ŒRFMåˆ†æ...")
        rfm_data = self.user_analyzer.calculate_rfm_features()
        rfm_segments = self.user_analyzer.rfm_segmentation()
        
        # 2. é«˜çº§ç‰¹å¾è®¡ç®—
        print("\nğŸ” è®¡ç®—é«˜çº§ç”¨æˆ·ç‰¹å¾...")
        user_features = self.user_analyzer.calculate_advanced_features()
        
        # 3. K-meansèšç±»
        print("\nğŸ” è¿›è¡ŒK-meansèšç±»...")
        clusters = self.user_analyzer.kmeans_clustering()
        
        # 4. ç”Ÿæˆç”¨æˆ·ç”»åƒ
        print("\nğŸ” ç”Ÿæˆç”¨æˆ·ç”»åƒ...")
        profiles = self.user_analyzer.generate_user_profiles()
        
        # 5. ä¿å­˜åˆ†æç»“æœ
        print("\nğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
        self.user_analyzer.save_analysis_results('analysis_results')
        
        self.results['user_analysis'] = {
            'rfm_data': rfm_data,
            'rfm_segments': rfm_segments,
            'user_features': user_features,
            'user_profiles': profiles
        }
        
        print("âœ… ç”¨æˆ·åˆ†æå®Œæˆ!")
        return True
    
    def train_algorithms(self):
        """è®­ç»ƒæ¨èç®—æ³•"""
        if self.data is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return
            
        print("\n" + "="*50)
        print("ğŸ¤– å¼€å§‹è®­ç»ƒæ¨èç®—æ³•")
        print("="*50)
        
        # 1. ååŒè¿‡æ»¤ç®—æ³•
        print("\nğŸ” è®­ç»ƒååŒè¿‡æ»¤ç®—æ³•...")
        
        # åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤
        user_cf = CollaborativeFiltering('user_based')
        user_cf.prepare_data(self.data)
        user_cf.calculate_similarity()
        self.algorithms['user_cf'] = user_cf
        print("âœ… åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤è®­ç»ƒå®Œæˆ")
        
        # åŸºäºç‰©å“çš„ååŒè¿‡æ»¤
        item_cf = CollaborativeFiltering('item_based')
        item_cf.prepare_data(self.data)
        item_cf.calculate_similarity()
        self.algorithms['item_cf'] = item_cf
        print("âœ… åŸºäºç‰©å“çš„ååŒè¿‡æ»¤è®­ç»ƒå®Œæˆ")
        
        # 2. Transformeråºåˆ—æ¨è
        print("\nğŸ” è®­ç»ƒTransformeråºåˆ—æ¨è...")
        transformer_rec = TransformerRecommender(
            hidden_size=64,
            num_layers=2,
            num_heads=4,
            max_seq_len=50
        )
        
        # è®­ç»ƒTransformeræ¨¡å‹
        try:
            losses = transformer_rec.train(self.data, epochs=30, batch_size=128)
            self.algorithms['transformer'] = transformer_rec
            print("âœ… Transformeråºåˆ—æ¨èè®­ç»ƒå®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ Transformerè®­ç»ƒå¤±è´¥: {e}")
        
        print(f"\nâœ… ç®—æ³•è®­ç»ƒå®Œæˆ! å…±è®­ç»ƒ {len(self.algorithms)} ä¸ªç®—æ³•")
        return True
    
    def evaluate_algorithms(self):
        """è¯„ä¼°ç®—æ³•æ€§èƒ½"""
        if not self.algorithms:
            print("âŒ è¯·å…ˆè®­ç»ƒç®—æ³•")
            return
            
        print("\n" + "="*50)
        print("ğŸ“Š å¼€å§‹ç®—æ³•æ€§èƒ½è¯„ä¼°")
        print("="*50)
        
        evaluation_results = {}
        
        # é€‰æ‹©æµ‹è¯•ç”¨æˆ·
        test_users = self.data['user_id'].unique()[:100]  # é€‰æ‹©å‰100ä¸ªç”¨æˆ·è¿›è¡Œæµ‹è¯•
        
        for alg_name, algorithm in self.algorithms.items():
            print(f"\nğŸ“Š è¯„ä¼°ç®—æ³•: {alg_name}")
            
            successful_recommendations = 0
            total_users = len(test_users)
            
            for user_id in test_users:
                try:
                    if alg_name in ['user_cf', 'item_cf']:
                        recommendations = algorithm.recommend(user_id, top_k=10)
                    elif alg_name == 'transformer':
                        recommendations = algorithm.recommend_for_user(self.data, user_id, top_k=10)
                    else:
                        recommendations = []
                    
                    if len(recommendations) > 0:
                        successful_recommendations += 1
                        
                except Exception as e:
                    continue
            
            coverage = successful_recommendations / total_users
            evaluation_results[alg_name] = {
                'coverage': coverage,
                'successful_recs': successful_recommendations,
                'total_users': total_users
            }
            
            print(f"   æ¨èè¦†ç›–ç‡: {coverage:.2%}")
            print(f"   æˆåŠŸæ¨èç”¨æˆ·æ•°: {successful_recommendations}/{total_users}")
        
        self.results['evaluation'] = evaluation_results
        print("\nâœ… ç®—æ³•è¯„ä¼°å®Œæˆ!")
        return evaluation_results
    
    def generate_recommendations(self, user_id, algorithm='auto', top_k=10):
        """ä¸ºæŒ‡å®šç”¨æˆ·ç”Ÿæˆæ¨è"""
        if not self.algorithms:
            print("âŒ è¯·å…ˆè®­ç»ƒç®—æ³•")
            return []
            
        print(f"\nğŸ¯ ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆæ¨è (ç®—æ³•: {algorithm}, Top-{top_k})")
        
        recommendations = {}
        
        # å¦‚æœé€‰æ‹©è‡ªåŠ¨ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨ç®—æ³•
        if algorithm == 'auto':
            algorithms_to_use = self.algorithms
        else:
            if algorithm in self.algorithms:
                algorithms_to_use = {algorithm: self.algorithms[algorithm]}
            else:
                print(f"âŒ ç®—æ³• {algorithm} ä¸å­˜åœ¨")
                return {}
        
        for alg_name, alg_instance in algorithms_to_use.items():
            try:
                if alg_name in ['user_cf', 'item_cf']:
                    recs = alg_instance.recommend(user_id, top_k=top_k)
                elif alg_name == 'transformer':
                    recs = alg_instance.recommend_for_user(self.data, user_id, top_k=top_k)
                else:
                    recs = []
                
                recommendations[alg_name] = recs
                print(f"âœ… {alg_name}: {len(recs)} ä¸ªæ¨è")
                
            except Exception as e:
                print(f"âŒ {alg_name} æ¨èå¤±è´¥: {e}")
                recommendations[alg_name] = []
        
        return recommendations
    
    def get_user_profile(self, user_id):
        """è·å–ç”¨æˆ·ç”»åƒ"""
        if self.data is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return None
            
        user_data = self.data[self.data['user_id'] == user_id]
        
        if len(user_data) == 0:
            print(f"âŒ ç”¨æˆ· {user_id} ä¸å­˜åœ¨")
            return None
        
        # è®¡ç®—ç”¨æˆ·åŸºç¡€ç‰¹å¾
        profile = {
            'user_id': user_id,
            'total_actions': len(user_data),
            'unique_items': user_data['item_id'].nunique(),
            'behavior_distribution': dict(user_data['behavior_type'].value_counts()),
            'active_days': user_data['date'].nunique() if 'date' in user_data.columns else None,
            'first_action': user_data['datetime'].min() if 'datetime' in user_data.columns else None,
            'last_action': user_data['datetime'].max() if 'datetime' in user_data.columns else None
        }
        
        # è®¡ç®—è½¬åŒ–ç‡
        behavior_counts = user_data['behavior_type'].value_counts()
        pv_count = behavior_counts.get('pv', 0)
        buy_count = behavior_counts.get('buy', 0)
        
        if pv_count > 0:
            profile['conversion_rate'] = buy_count / pv_count
        else:
            profile['conversion_rate'] = 0
        
        return profile
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ¨èç³»ç»Ÿåˆ†ææµç¨‹")
        print("=" * 60)
        
        # 1. æ•°æ®åŠ è½½
        if self.data is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return False
        
        # 2. ç”¨æˆ·åˆ†æ
        success = self.analyze_users()
        if not success:
            return False
        
        # 3. ç®—æ³•è®­ç»ƒ
        success = self.train_algorithms()
        if not success:
            return False
        
        # 4. ç®—æ³•è¯„ä¼°
        self.evaluate_algorithms()
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        self.generate_summary_report()
        
        print(f"\nğŸ‰ å®Œæ•´åˆ†ææµç¨‹æ‰§è¡Œå®Œæˆ!")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ° analysis_results ç›®å½•")
        
        return True
    
    def generate_summary_report(self):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆåˆ†ææ€»ç»“æŠ¥å‘Š...")
        
        report = []
        report.append("# ç”µå•†ç”¨æˆ·è¡Œä¸ºæ¨èç³»ç»Ÿåˆ†ææŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("\n## æ•°æ®æ¦‚å†µ")
        
        if self.data is not None:
            report.append(f"- æ€»è®°å½•æ•°: {len(self.data):,}")
            report.append(f"- ç”¨æˆ·æ•°é‡: {self.data['user_id'].nunique():,}")
            report.append(f"- å•†å“æ•°é‡: {self.data['item_id'].nunique():,}")
            
            behavior_dist = self.data['behavior_type'].value_counts()
            report.append(f"- è¡Œä¸ºåˆ†å¸ƒ: {dict(behavior_dist)}")
        
        report.append("\n## ç®—æ³•æ€§èƒ½")
        if 'evaluation' in self.results:
            for alg_name, metrics in self.results['evaluation'].items():
                report.append(f"- {alg_name}: è¦†ç›–ç‡ {metrics['coverage']:.2%}")
        
        report.append("\n## ç”¨æˆ·åˆ†ç¾¤")
        if 'user_analysis' in self.results and 'user_profiles' in self.results['user_analysis']:
            profiles = self.results['user_analysis']['user_profiles']
            for segment, data in profiles.items():
                report.append(f"- {segment}: {data['ç”¨æˆ·æ•°é‡']} ç”¨æˆ· ({data['å æ¯”']:.1f}%)")
        
        report.append("\n## å»ºè®®")
        report.append("1. é’ˆå¯¹ä¸åŒç”¨æˆ·åˆ†ç¾¤åˆ¶å®šå·®å¼‚åŒ–æ¨èç­–ç•¥")
        report.append("2. é‡ç‚¹å…³æ³¨æµå¤±é£é™©ç”¨æˆ·çš„æŒ½å›")
        report.append("3. æŒç»­ä¼˜åŒ–ç®—æ³•å‚æ•°æå‡æ¨èæ•ˆæœ")
        report.append("4. ç»“åˆä¸šåŠ¡åœºæ™¯é€‰æ‹©åˆé€‚çš„æ¨èç®—æ³•")
        
        # ä¿å­˜æŠ¥å‘Š
        os.makedirs('analysis_results', exist_ok=True)
        with open('analysis_results/summary_report.md', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print("âœ… æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ° analysis_results/summary_report.md")

def demo_quick_start():
    """å¿«é€Ÿå¼€å§‹æ¼”ç¤º"""
    print("ğŸš€ æ¨èç³»ç»Ÿå¿«é€Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("ğŸ“Š ç”Ÿæˆç¤ºä¾‹æ•°æ®...")
    np.random.seed(42)
    
    n_users, n_items = 1000, 500
    data_list = []
    
    for _ in range(10000):
        user_id = np.random.randint(1, n_users + 1)
        item_id = np.random.randint(1, n_items + 1)
        behavior_type = np.random.choice(['pv', 'cart', 'fav', 'buy'], 
                                       p=[0.7, 0.15, 0.1, 0.05])
        timestamp = pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 30))
        
        data_list.append({
            'user_id': user_id,
            'item_id': item_id,
            'behavior_type': behavior_type,
            'datetime': timestamp
        })
    
    demo_data = pd.DataFrame(data_list)
    demo_data.to_csv('demo_data.csv', index=False)
    print(f"âœ… ç¤ºä¾‹æ•°æ®å·²ç”Ÿæˆ: demo_data.csv ({len(demo_data)} æ¡è®°å½•)")
    
    # åˆå§‹åŒ–æ¨èç³»ç»Ÿ
    recommender = ECommerceRecommenderSystem('demo_data.csv')
    
    # åŠ è½½æ•°æ®
    recommender.load_data()
    
    # è¿è¡Œå®Œæ•´åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
    print("\nğŸ” è¿è¡Œç”¨æˆ·åˆ†æ...")
    recommender.analyze_users()
    
    print("\nğŸ¤– è®­ç»ƒæ¨èç®—æ³•...")
    recommender.train_algorithms()
    
    print("\nğŸ“Š è¯„ä¼°ç®—æ³•æ€§èƒ½...")
    recommender.evaluate_algorithms()
    
    # ä¸ºç¤ºä¾‹ç”¨æˆ·ç”Ÿæˆæ¨è
    test_user = demo_data['user_id'].iloc[0]
    print(f"\nğŸ¯ ä¸ºç”¨æˆ· {test_user} ç”Ÿæˆæ¨è...")
    recommendations = recommender.generate_recommendations(test_user, algorithm='auto', top_k=5)
    
    for alg_name, recs in recommendations.items():
        print(f"  {alg_name}: {recs}")
    
    # ç”ŸæˆæŠ¥å‘Š
    recommender.generate_summary_report()
    
    print("\nâœ… å¿«é€Ÿæ¼”ç¤ºå®Œæˆ!")
    print("ğŸ’¡ æç¤º: è¿è¡Œ 'streamlit run recommendation_dashboard.py' å¯åŠ¨å¯è§†åŒ–ç•Œé¢")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›’ ç”µå•†ç”¨æˆ·è¡Œä¸ºæ¨èç³»ç»Ÿ")
    print("=" * 60)
    print("é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. å¿«é€Ÿæ¼”ç¤º (ä½¿ç”¨ç¤ºä¾‹æ•°æ®)")
    print("2. è‡ªå®šä¹‰æ•°æ®åˆ†æ")
    print("3. å¯åŠ¨å¯è§†åŒ–ç•Œé¢")
    
    choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice == '1':
        demo_quick_start()
    elif choice == '2':
        data_path = input("è¯·è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„: ").strip()
        if os.path.exists(data_path):
            recommender = ECommerceRecommenderSystem(data_path)
            recommender.load_data()
            recommender.run_complete_analysis()
        else:
            print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
    elif choice == '3':
        print("ğŸ’¡ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨å¯è§†åŒ–ç•Œé¢:")
        print("streamlit run recommendation_dashboard.py")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main() 